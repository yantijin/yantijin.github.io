---
title: 模型评估与选择
date: 2018-11-13 23:19:44
tags: machine learning
categories:
- machine learning
- 模型评估与选择
---

## 本章基本概念

* **错误率(error rate)**: 在m个样本中假设有a个样本分类错误，则错误率$E = a/m$,相应地，$1-a/m$称为**精度(accuracy)**
* 实际预测输出与样本真实输出的误差称为“误差”(error),在训练集上的误差称为**训练(training)误差\经验(empirical)误差**，在新样本上的误差称为**泛化误差**
* **过拟合overfitting**：泛化能力很差；**欠拟合(underfitting)**:对训练样本的一般性质尚未学习好。

## 评估方法

* 注意测试集和训练集的数据分布应该尽量保持一致，一般采用分层采样(stratified sampling)

### 留出法

* 将数据集D拆分为两个互斥的集合，其中一个集合为训练集S，另一个为测试集T，$D = S\cup T,S\cap T =\emptyset$
* 一般采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果

### 交叉验证法/K折交叉验证

* 将数据集划分为k个大小相似的互斥子集，即$D = D_1\cup D_2\cup ... \cup D_k,D_i\cap D_j =\emptyset(i\neq j)$,注意每个子集$D_i$都尽可能保持数据分布的一致性
* 与留出法相似，通常要随机使用不同 划分重复p次，最终的结果是这p次k折交叉验证结果的均值。

### 自助法

* 对于样本集D，采用**有放回采样**：每次随机取一个，然后放回，直到构成一个新的样本集$D'$,样本在m次采样中始终不被采集到的概率为$(1-\frac{1}{m})^m = \frac{1}{e}\approx 0.368$,故而约有36.8%的样本未出现在D'中，用$D/D'$用作测试集

### 总结

* 自助法在数据集较小，难以有效划分训练/测试集时很有用，而且能够从初始集中产生多个不同的训练集，对于集成学习等方法有很大的好处；但是他改变了初始数据集的分布，会引入**估计偏差(estimation error)**，因此在数据量组都的情况下，推荐使用留出法和交叉验证法。

## 性能度量

### 回归任务

* **回归**任务最常用的性能度量就是**“均方误差(mean squared error)”**
  $$
  E(f;D)=\frac{1}{m}\sum^m_{i=1}(f(x_i)-y_i)^2
  $$
  更一般地，对于数据分布D和概率密度函数p(.),均方误差可描述为
  $$
  E(f;D) = \int_{x\sim D}(f(x)-y)^2p(x)dx
  $$





### 分类任务

* 对于样例集D，

  **错误率**定义为
  $$
  E(f;D)=\frac{1}{m}\sum^m_{i=1}\|(f(x_i)\neq y_i)
  $$
  **精度**定义为
  $$
  acc(f;D) = \frac{1}{m}\sum^m_{i=1}\|(f(x_i) = y_i)
  $$
  更一般地，对于数据分布D和概率密度函数p(.)，错误率和精度可分别描述为
  $$
  E(f;D)=\int_{x\sim D}\|(f(x)\neq y)p(x)dx\\
  acc(f;D) = \int_{x\sim D}\|(f(x) = y)p(x)dx = 1-E(f;D)
  $$





* **混淆矩阵(confusion matrix)**:

  | 真实情况 | 预测结果   | 预测结果   |
  | -------- | ---------- | ---------- |
  |          | 正例       | 反例       |
  | 正例     | TP(真正例) | FN(假反例) |
  | 反例     | FP(假正例) | TN(真反例) |

  **查准率P**: $P = \frac{TP}{TP+FP}$

  **查全率R**：$R = \frac{TP}{TP+FN}$

